{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"I have a THIRD vision. India must stand up to the world. Because I believe that, unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand. My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr.Brahm Prakash, father of nuclear material. I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\yuvra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a THIRD vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that, unless India stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of space, Professor Satish Dhawan, who succeeded him and Dr.Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "from  nltk.corpus import stopwords\n",
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('THIRD', 'VBP'), ('vision', 'NN'), ('.', '.')]\n",
      "[('India', 'NNP'), ('must', 'MD'), ('stand', 'VB'), ('world', 'NN'), ('.', '.')]\n",
      "[('Because', 'IN'), ('I', 'PRP'), ('believe', 'VBP'), (',', ','), ('unless', 'IN'), ('India', 'NNP'), ('stands', 'VBZ'), ('world', 'NN'), (',', ','), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP'), ('.', '.')]\n",
      "[('Only', 'RB'), ('strength', 'NN'), ('respects', 'NNS'), ('strength', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('must', 'MD'), ('strong', 'JJ'), ('military', 'JJ'), ('power', 'NN'), ('also', 'RB'), ('economic', 'JJ'), ('power', 'NN'), ('.', '.')]\n",
      "[('Both', 'DT'), ('must', 'MD'), ('go', 'VB'), ('hand-in-hand', 'NN'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('good', 'JJ'), ('fortune', 'NN'), ('worked', 'VBD'), ('three', 'CD'), ('great', 'JJ'), ('minds', 'NNS'), ('.', '.')]\n",
      "[('Dr.', 'NNP'), ('Vikram', 'NNP'), ('Sarabhai', 'NNP'), ('Dept', 'NNP'), ('.', '.')]\n",
      "[('space', 'NN'), (',', ','), ('Professor', 'NNP'), ('Satish', 'NNP'), ('Dhawan', 'NNP'), (',', ','), ('succeeded', 'VBD'), ('Dr.Brahm', 'NNP'), ('Prakash', 'NNP'), (',', ','), ('father', 'RB'), ('nuclear', 'JJ'), ('material', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('lucky', 'VBP'), ('worked', 'VBD'), ('three', 'CD'), ('closely', 'RB'), ('consider', 'VBP'), ('great', 'JJ'), ('opportunity', 'NN'), ('life', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# finding out the POS tags for each word  in the sentence\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words('english'))]\n",
    "    #sentences[i]=''.join(words)\n",
    "    pos_tag=nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taj', 'Mahal', 'is', 'a', 'beautiful', 'Monument']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Taj Mahal is a beautiful Monument\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('Monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# applying pos tag to a single sentences\n",
    "print(nltk.pos_tag(\"Taj Mahal is a beautiful Monument\".split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
